{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN+Catboost.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqcUzNt5PLm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UeNbnQsP3eY",
        "colab_type": "code",
        "outputId": "c841a26f-4c9e-42d1-cda5-ed658d6ad5b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "'''Trains a simple deep NN on the MNIST dataset.\n",
        "Gets to 98.40% test accuracy after 20 epochs\n",
        "(there is *a lot* of margin for parameter tuning).\n",
        "2 seconds per epoch on a K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.2450 - acc: 0.9240 - val_loss: 0.1085 - val_acc: 0.9675\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.1018 - acc: 0.9692 - val_loss: 0.0859 - val_acc: 0.9760\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0743 - acc: 0.9774 - val_loss: 0.0799 - val_acc: 0.9767\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0597 - acc: 0.9821 - val_loss: 0.0818 - val_acc: 0.9769\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0513 - acc: 0.9849 - val_loss: 0.0873 - val_acc: 0.9786\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0432 - acc: 0.9872 - val_loss: 0.0761 - val_acc: 0.9800\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0389 - acc: 0.9889 - val_loss: 0.0849 - val_acc: 0.9812\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0353 - acc: 0.9901 - val_loss: 0.0831 - val_acc: 0.9838\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0324 - acc: 0.9910 - val_loss: 0.0943 - val_acc: 0.9812\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0293 - acc: 0.9915 - val_loss: 0.0967 - val_acc: 0.9815\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0285 - acc: 0.9922 - val_loss: 0.0842 - val_acc: 0.9833\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0252 - acc: 0.9931 - val_loss: 0.0902 - val_acc: 0.9835\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0235 - acc: 0.9934 - val_loss: 0.0948 - val_acc: 0.9822\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0208 - acc: 0.9941 - val_loss: 0.0989 - val_acc: 0.9824\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0230 - acc: 0.9939 - val_loss: 0.0901 - val_acc: 0.9835\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0201 - acc: 0.9944 - val_loss: 0.1005 - val_acc: 0.9853\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0197 - acc: 0.9947 - val_loss: 0.1165 - val_acc: 0.9827\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0196 - acc: 0.9951 - val_loss: 0.1168 - val_acc: 0.9813\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0178 - acc: 0.9954 - val_loss: 0.1137 - val_acc: 0.9829\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0184 - acc: 0.9951 - val_loss: 0.1259 - val_acc: 0.9829\n",
            "Test loss: 0.12591867105730895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B0DuywPP4I8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def get_nth_layer_output(input_data, n):\n",
        "    get_layer_output = K.function([model.layers[0].input],\n",
        "                                    [model.layers[n].output])\n",
        "    layer_output = get_layer_output([input_data])[0]\n",
        "\n",
        "    return layer_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVmAh3cATE9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_layer_output = get_nth_layer_output(x_train, 3)\n",
        "train_layer_output_last = get_nth_layer_output(x_train, 4)\n",
        "\n",
        "test_layer_output = get_nth_layer_output(x_test, 3)\n",
        "test_layer_output_last = get_nth_layer_output(x_test, 4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfY0RjieRGSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df_train = pd.DataFrame(train_layer_output)\n",
        "df2_train = pd.DataFrame(train_layer_output_last)\n",
        "df_train = pd.concat([df_train, df2_train], axis=1)\n",
        "\n",
        "df_test = pd.DataFrame(test_layer_output)\n",
        "df2_test = pd.DataFrame(test_layer_output_last)\n",
        "df_test = pd.concat([df_test, df2_test], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1p7h4vRUXAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train_, y_train_), (x_test_, y_test_) = mnist.load_data()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0jzCYcbRQQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_train = pd.DataFrame(y_train_, columns=['target'])\n",
        "label_test = pd.DataFrame(y_test_, columns=['target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9lfJb77Su98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gukX5FcKUBPz",
        "colab_type": "code",
        "outputId": "17348eee-a5b6-4af1-a909-d1d2448f6b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/c4/586923de4634f88a31fd1b4966e15707a912b98b6f4566651b5ef58f36b5/catboost-0.20.2-cp36-none-manylinux1_x86_64.whl (63.9MB)\n",
            "\u001b[K     |████████████████████████████████| 63.9MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.25.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.17.5)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (42.0.2)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.20.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWlgFDIRWxT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbKvJH93UCqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CatBoostClassifier(iterations=3000, \n",
        "                                   verbose=10,\n",
        "                                   random_seed=43,\n",
        "                                   od_type='Iter',\n",
        "                                   od_wait=500,\n",
        "                                   train_dir=f'model_nn',\n",
        "                                   task_type='GPU',\n",
        "                                   )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CShMHlL5XN6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.columns = list(range(0, len(df_train.columns)))\n",
        "df_test.columns = list(range(0, len(df_test.columns)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApL_JP21Wujg",
        "colab_type": "code",
        "outputId": "9480cee7-6f6b-420e-ad12-bd91e9bd9f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(df_train, label_train,\n",
        "                    eval_set=(df_test, label_test), \n",
        "                    use_best_model=True,\n",
        "                    )"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 2.1245753\ttest: 2.1272375\tbest: 2.1272375 (0)\ttotal: 65.9ms\tremaining: 3m 17s\n",
            "10:\tlearn: 1.2200979\ttest: 1.2418470\tbest: 1.2418470 (10)\ttotal: 490ms\tremaining: 2m 13s\n",
            "20:\tlearn: 0.8186812\ttest: 0.8486076\tbest: 0.8486076 (20)\ttotal: 819ms\tremaining: 1m 56s\n",
            "30:\tlearn: 0.5811436\ttest: 0.6167817\tbest: 0.6167817 (30)\ttotal: 1.15s\tremaining: 1m 50s\n",
            "40:\tlearn: 0.4254114\ttest: 0.4648545\tbest: 0.4648545 (40)\ttotal: 1.5s\tremaining: 1m 48s\n",
            "50:\tlearn: 0.3168338\ttest: 0.3595822\tbest: 0.3595822 (50)\ttotal: 1.85s\tremaining: 1m 46s\n",
            "60:\tlearn: 0.2397645\ttest: 0.2852355\tbest: 0.2852355 (60)\ttotal: 2.2s\tremaining: 1m 45s\n",
            "70:\tlearn: 0.1834396\ttest: 0.2312315\tbest: 0.2312315 (70)\ttotal: 2.55s\tremaining: 1m 45s\n",
            "80:\tlearn: 0.1412935\ttest: 0.1910785\tbest: 0.1910785 (80)\ttotal: 2.89s\tremaining: 1m 44s\n",
            "90:\tlearn: 0.1097638\ttest: 0.1612249\tbest: 0.1612249 (90)\ttotal: 3.26s\tremaining: 1m 44s\n",
            "100:\tlearn: 0.0860549\ttest: 0.1389403\tbest: 0.1389403 (100)\ttotal: 3.62s\tremaining: 1m 43s\n",
            "110:\tlearn: 0.0678793\ttest: 0.1219975\tbest: 0.1219975 (110)\ttotal: 3.99s\tremaining: 1m 43s\n",
            "120:\tlearn: 0.0541826\ttest: 0.1096371\tbest: 0.1096371 (120)\ttotal: 4.37s\tremaining: 1m 43s\n",
            "130:\tlearn: 0.0437686\ttest: 0.1001853\tbest: 0.1001853 (130)\ttotal: 4.76s\tremaining: 1m 44s\n",
            "140:\tlearn: 0.0357882\ttest: 0.0932720\tbest: 0.0932720 (140)\ttotal: 5.17s\tremaining: 1m 44s\n",
            "150:\tlearn: 0.0295124\ttest: 0.0879836\tbest: 0.0879836 (150)\ttotal: 5.57s\tremaining: 1m 45s\n",
            "160:\tlearn: 0.0248915\ttest: 0.0840843\tbest: 0.0840843 (160)\ttotal: 5.97s\tremaining: 1m 45s\n",
            "170:\tlearn: 0.0212492\ttest: 0.0811122\tbest: 0.0811122 (170)\ttotal: 6.38s\tremaining: 1m 45s\n",
            "180:\tlearn: 0.0183326\ttest: 0.0788653\tbest: 0.0788653 (180)\ttotal: 6.77s\tremaining: 1m 45s\n",
            "190:\tlearn: 0.0160813\ttest: 0.0773296\tbest: 0.0773296 (190)\ttotal: 7.19s\tremaining: 1m 45s\n",
            "200:\tlearn: 0.0142288\ttest: 0.0760787\tbest: 0.0760787 (200)\ttotal: 7.61s\tremaining: 1m 45s\n",
            "210:\tlearn: 0.0129062\ttest: 0.0751728\tbest: 0.0751728 (210)\ttotal: 8s\tremaining: 1m 45s\n",
            "220:\tlearn: 0.0117743\ttest: 0.0746229\tbest: 0.0746229 (220)\ttotal: 8.39s\tremaining: 1m 45s\n",
            "230:\tlearn: 0.0107839\ttest: 0.0741187\tbest: 0.0741187 (230)\ttotal: 8.77s\tremaining: 1m 45s\n",
            "240:\tlearn: 0.0100075\ttest: 0.0737820\tbest: 0.0737820 (240)\ttotal: 9.16s\tremaining: 1m 44s\n",
            "250:\tlearn: 0.0094423\ttest: 0.0735791\tbest: 0.0735791 (250)\ttotal: 9.49s\tremaining: 1m 43s\n",
            "260:\tlearn: 0.0088887\ttest: 0.0733420\tbest: 0.0733420 (260)\ttotal: 9.87s\tremaining: 1m 43s\n",
            "270:\tlearn: 0.0084801\ttest: 0.0732279\tbest: 0.0732279 (270)\ttotal: 10.2s\tremaining: 1m 43s\n",
            "280:\tlearn: 0.0079721\ttest: 0.0730877\tbest: 0.0730877 (280)\ttotal: 10.6s\tremaining: 1m 42s\n",
            "290:\tlearn: 0.0075942\ttest: 0.0730131\tbest: 0.0730131 (290)\ttotal: 11s\tremaining: 1m 42s\n",
            "300:\tlearn: 0.0072813\ttest: 0.0729994\tbest: 0.0729677 (299)\ttotal: 11.4s\tremaining: 1m 41s\n",
            "310:\tlearn: 0.0069797\ttest: 0.0729415\tbest: 0.0729415 (310)\ttotal: 11.8s\tremaining: 1m 41s\n",
            "320:\tlearn: 0.0067193\ttest: 0.0728873\tbest: 0.0728873 (320)\ttotal: 12.1s\tremaining: 1m 41s\n",
            "330:\tlearn: 0.0065039\ttest: 0.0729073\tbest: 0.0728873 (320)\ttotal: 12.5s\tremaining: 1m 40s\n",
            "340:\tlearn: 0.0062813\ttest: 0.0729513\tbest: 0.0728873 (320)\ttotal: 12.8s\tremaining: 1m 40s\n",
            "350:\tlearn: 0.0061034\ttest: 0.0729374\tbest: 0.0728873 (320)\ttotal: 13.2s\tremaining: 1m 39s\n",
            "360:\tlearn: 0.0059422\ttest: 0.0729506\tbest: 0.0728873 (320)\ttotal: 13.6s\tremaining: 1m 39s\n",
            "370:\tlearn: 0.0058000\ttest: 0.0729481\tbest: 0.0728873 (320)\ttotal: 13.9s\tremaining: 1m 38s\n",
            "380:\tlearn: 0.0056069\ttest: 0.0730634\tbest: 0.0728873 (320)\ttotal: 14.3s\tremaining: 1m 38s\n",
            "390:\tlearn: 0.0054731\ttest: 0.0730519\tbest: 0.0728873 (320)\ttotal: 14.7s\tremaining: 1m 37s\n",
            "400:\tlearn: 0.0053431\ttest: 0.0730749\tbest: 0.0728873 (320)\ttotal: 15s\tremaining: 1m 37s\n",
            "410:\tlearn: 0.0052568\ttest: 0.0731521\tbest: 0.0728873 (320)\ttotal: 15.4s\tremaining: 1m 36s\n",
            "420:\tlearn: 0.0051549\ttest: 0.0730835\tbest: 0.0728873 (320)\ttotal: 15.7s\tremaining: 1m 36s\n",
            "430:\tlearn: 0.0050388\ttest: 0.0731356\tbest: 0.0728873 (320)\ttotal: 16.1s\tremaining: 1m 36s\n",
            "440:\tlearn: 0.0049564\ttest: 0.0731392\tbest: 0.0728873 (320)\ttotal: 16.5s\tremaining: 1m 35s\n",
            "450:\tlearn: 0.0048819\ttest: 0.0731796\tbest: 0.0728873 (320)\ttotal: 16.8s\tremaining: 1m 35s\n",
            "460:\tlearn: 0.0048092\ttest: 0.0731552\tbest: 0.0728873 (320)\ttotal: 17.2s\tremaining: 1m 34s\n",
            "470:\tlearn: 0.0047338\ttest: 0.0731353\tbest: 0.0728873 (320)\ttotal: 17.5s\tremaining: 1m 33s\n",
            "480:\tlearn: 0.0046659\ttest: 0.0731860\tbest: 0.0728873 (320)\ttotal: 17.8s\tremaining: 1m 33s\n",
            "490:\tlearn: 0.0046116\ttest: 0.0731965\tbest: 0.0728873 (320)\ttotal: 18.2s\tremaining: 1m 32s\n",
            "500:\tlearn: 0.0045624\ttest: 0.0731993\tbest: 0.0728873 (320)\ttotal: 18.5s\tremaining: 1m 32s\n",
            "510:\tlearn: 0.0044740\ttest: 0.0732333\tbest: 0.0728873 (320)\ttotal: 18.9s\tremaining: 1m 31s\n",
            "520:\tlearn: 0.0044127\ttest: 0.0732102\tbest: 0.0728873 (320)\ttotal: 19.2s\tremaining: 1m 31s\n",
            "530:\tlearn: 0.0043546\ttest: 0.0732215\tbest: 0.0728873 (320)\ttotal: 19.5s\tremaining: 1m 30s\n",
            "540:\tlearn: 0.0043077\ttest: 0.0732199\tbest: 0.0728873 (320)\ttotal: 19.9s\tremaining: 1m 30s\n",
            "550:\tlearn: 0.0042258\ttest: 0.0732570\tbest: 0.0728873 (320)\ttotal: 20.3s\tremaining: 1m 30s\n",
            "560:\tlearn: 0.0041672\ttest: 0.0733186\tbest: 0.0728873 (320)\ttotal: 20.6s\tremaining: 1m 29s\n",
            "570:\tlearn: 0.0041111\ttest: 0.0733254\tbest: 0.0728873 (320)\ttotal: 21s\tremaining: 1m 29s\n",
            "580:\tlearn: 0.0040500\ttest: 0.0733505\tbest: 0.0728873 (320)\ttotal: 21.3s\tremaining: 1m 28s\n",
            "590:\tlearn: 0.0039843\ttest: 0.0733865\tbest: 0.0728873 (320)\ttotal: 21.7s\tremaining: 1m 28s\n",
            "600:\tlearn: 0.0039303\ttest: 0.0733382\tbest: 0.0728873 (320)\ttotal: 22s\tremaining: 1m 27s\n",
            "610:\tlearn: 0.0038634\ttest: 0.0733516\tbest: 0.0728873 (320)\ttotal: 22.4s\tremaining: 1m 27s\n",
            "620:\tlearn: 0.0038228\ttest: 0.0733530\tbest: 0.0728873 (320)\ttotal: 22.7s\tremaining: 1m 26s\n",
            "630:\tlearn: 0.0037570\ttest: 0.0733961\tbest: 0.0728873 (320)\ttotal: 23.1s\tremaining: 1m 26s\n",
            "640:\tlearn: 0.0037151\ttest: 0.0734748\tbest: 0.0728873 (320)\ttotal: 23.4s\tremaining: 1m 26s\n",
            "650:\tlearn: 0.0036688\ttest: 0.0735050\tbest: 0.0728873 (320)\ttotal: 23.7s\tremaining: 1m 25s\n",
            "660:\tlearn: 0.0036285\ttest: 0.0735741\tbest: 0.0728873 (320)\ttotal: 24.1s\tremaining: 1m 25s\n",
            "670:\tlearn: 0.0036007\ttest: 0.0735615\tbest: 0.0728873 (320)\ttotal: 24.4s\tremaining: 1m 24s\n",
            "680:\tlearn: 0.0035524\ttest: 0.0735978\tbest: 0.0728873 (320)\ttotal: 24.8s\tremaining: 1m 24s\n",
            "690:\tlearn: 0.0035205\ttest: 0.0736371\tbest: 0.0728873 (320)\ttotal: 25.1s\tremaining: 1m 23s\n",
            "700:\tlearn: 0.0034778\ttest: 0.0736736\tbest: 0.0728873 (320)\ttotal: 25.5s\tremaining: 1m 23s\n",
            "710:\tlearn: 0.0034374\ttest: 0.0736887\tbest: 0.0728873 (320)\ttotal: 25.8s\tremaining: 1m 23s\n",
            "720:\tlearn: 0.0033928\ttest: 0.0736869\tbest: 0.0728873 (320)\ttotal: 26.2s\tremaining: 1m 22s\n",
            "730:\tlearn: 0.0033380\ttest: 0.0737840\tbest: 0.0728873 (320)\ttotal: 26.5s\tremaining: 1m 22s\n",
            "740:\tlearn: 0.0033103\ttest: 0.0738194\tbest: 0.0728873 (320)\ttotal: 26.9s\tremaining: 1m 21s\n",
            "750:\tlearn: 0.0032849\ttest: 0.0738240\tbest: 0.0728873 (320)\ttotal: 27.2s\tremaining: 1m 21s\n",
            "760:\tlearn: 0.0032446\ttest: 0.0738852\tbest: 0.0728873 (320)\ttotal: 27.6s\tremaining: 1m 21s\n",
            "770:\tlearn: 0.0031997\ttest: 0.0740148\tbest: 0.0728873 (320)\ttotal: 27.9s\tremaining: 1m 20s\n",
            "780:\tlearn: 0.0031654\ttest: 0.0740358\tbest: 0.0728873 (320)\ttotal: 28.2s\tremaining: 1m 20s\n",
            "790:\tlearn: 0.0031334\ttest: 0.0740512\tbest: 0.0728873 (320)\ttotal: 28.6s\tremaining: 1m 19s\n",
            "800:\tlearn: 0.0030865\ttest: 0.0741079\tbest: 0.0728873 (320)\ttotal: 29s\tremaining: 1m 19s\n",
            "810:\tlearn: 0.0030570\ttest: 0.0741355\tbest: 0.0728873 (320)\ttotal: 29.3s\tremaining: 1m 19s\n",
            "820:\tlearn: 0.0030112\ttest: 0.0742071\tbest: 0.0728873 (320)\ttotal: 29.7s\tremaining: 1m 18s\n",
            "bestTest = 0.07288727417\n",
            "bestIteration = 320\n",
            "Shrink model to first 321 iterations.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f67992c47f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a2JHVaEXASF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YgBfB65Zjiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}